{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "import PPO_pytorch as PPO\n",
    "import gym\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "\n",
    "PPO = PPO.Trainer(actor_dims=[128,128], critic_dims=[128,128], game_name=\"CartPole-v0\", is_conti=False, \n",
    "                    path=\"/home/sk851/PPO_CartPole.pt\", load_model=False, device=device, maxframe=300000, \n",
    "                    verbose_freq=300, eps_clip=0.2, K_epoch=3, len_traj=5, size_batch=5, num_batch=32, lr=0.0005)\n",
    "\n",
    "PPO.train()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0194ccddd98451f8124bfd526c9348e"
      },
      "text/plain": [
       "  0%|          | 0/300000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean score over last 300 episodes was 21.170\n",
      "Mean score over last 300 episodes was 23.800\n",
      "Mean score over last 300 episodes was 28.490\n",
      "Mean score over last 300 episodes was 38.010\n",
      "Mean score over last 300 episodes was 52.093\n",
      "Mean score over last 300 episodes was 62.007\n",
      "Mean score over last 300 episodes was 27.160\n",
      "Mean score over last 300 episodes was 142.810\n",
      "Policy weight was saved\n",
      "Mean score over last 300 episodes was 105.863\n",
      "Mean score over last 300 episodes was 71.023\n",
      "Mean score over last 300 episodes was 98.273\n",
      "Mean score over last 300 episodes was 137.870\n",
      "Mean score over last 300 episodes was 130.933\n",
      "Policy weight was saved\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Check actual play of trained DQN\n",
    "# Start virtual display to enable env.render() with remote server connection\n",
    "from pyvirtualdisplay import Display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()\n",
    "\n",
    "# Play game & save game play as .gif file\n",
    "PPO.play(path='/home/sk851/PPO_CartPole.pt', save_path='/home/sk851', num_episodes=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model loading completed\n",
      "Episode reward : 200.000\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('test': conda)"
  },
  "interpreter": {
   "hash": "613189b9447b40282886222006ee8b14fcbe993fdc86fe1dc10aaac86284b79c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}